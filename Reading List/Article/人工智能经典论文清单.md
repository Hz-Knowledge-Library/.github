# äººå·¥æ™ºèƒ½ç»å…¸è®ºæ–‡æ¸…å•

**è¯´æ˜ï¼š**
- ğŸ“Š = ç»¼è¿°æ–‡ç« ï¼ˆSurvey/Reviewï¼‰
- â­ = å¼€åˆ›é¢†åŸŸçš„å¥ åŸºæ€§è®ºæ–‡
- ğŸ”¥ = é«˜å¼•ç”¨ç»å…¸è®ºæ–‡
- ğŸ† = å›¾çµå¥–ç›¸å…³å·¥ä½œ

æœ¬æ¸…å•ç²¾é€‰äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ å„é¢†åŸŸæœ€å…·å½±å“åŠ›çš„è®ºæ–‡ï¼Œæ’é™¤æ°´æ–‡å’Œæœªç»è€ƒè¯çš„æ–‡ç« ã€‚

---

## ç›®å½•

1. [AIåŸºç¡€ä¸å†å²](#aiåŸºç¡€ä¸å†å²)
2. [æœºå™¨å­¦ä¹ åŸºç¡€](#æœºå™¨å­¦ä¹ åŸºç¡€)
3. [æ·±åº¦å­¦ä¹ ](#æ·±åº¦å­¦ä¹ )
4. [è®¡ç®—æœºè§†è§‰](#è®¡ç®—æœºè§†è§‰)
5. [è‡ªç„¶è¯­è¨€å¤„ç†](#è‡ªç„¶è¯­è¨€å¤„ç†)
6. [å¼ºåŒ–å­¦ä¹ ](#å¼ºåŒ–å­¦ä¹ )
7. [ç”Ÿæˆæ¨¡å‹](#ç”Ÿæˆæ¨¡å‹)
8. [å›¾ç¥ç»ç½‘ç»œ](#å›¾ç¥ç»ç½‘ç»œ)
9. [å…ƒå­¦ä¹ ä¸è¿ç§»å­¦ä¹ ](#å…ƒå­¦ä¹ ä¸è¿ç§»å­¦ä¹ )
10. [AIåº”ç”¨ä¸ç³»ç»Ÿ](#aiåº”ç”¨ä¸ç³»ç»Ÿ)

---

## AIåŸºç¡€ä¸å†å²

### AIçš„è¯ç”Ÿ
- [ ] **Computing Machinery and Intelligence** - *Alan Turing* (1950) â­ğŸ†ğŸ”¥
  - Turingæµ‹è¯•
  - AIå“²å­¦åŸºç¡€
  - *Mind* 59(236)

- [ ] **A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence** - *John McCarthy et al.* (1955) â­ğŸ†
  - "äººå·¥æ™ºèƒ½"æœ¯è¯­é¦–æ¬¡æå‡º
  - Dartmouthä¼šè®®ææ¡ˆ

### æ—©æœŸAI
- [ ] **Programs with Common Sense** - *John McCarthy* (1959) â­ğŸ†
  - å¸¸è¯†æ¨ç†
  - *Mechanisation of Thought Processes*

- [ ] **Steps Toward Artificial Intelligence** - *Marvin Minsky* (1961) â­ğŸ†
  - AIæ—©æœŸç»¼è¿°
  - *Proceedings of the IRE* 49

- [ ] **Perceptrons** - *Marvin Minsky, Seymour Papert* (1969) â­ğŸ†
  - æ„ŸçŸ¥æœºçš„å±€é™æ€§
  - å¯¼è‡´AIç¬¬ä¸€æ¬¡å¯’å†¬

### çŸ¥è¯†è¡¨ç¤ºä¸æ¨ç†
- [ ] **A Computational Approach to Commonsense Reasoning** - *Pat Hayes* (1973-1985) ğŸ†
  - Naive physics
  - å¸¸è¯†æ¨ç†ç³»ç»Ÿ

- [ ] **Semantic Networks** - *Ross Quillian* (1968) â­
  - è¯­ä¹‰ç½‘ç»œ
  - *Semantic Information Processing*

### ç»¼è¿°æ–‡ç« 
- [ ] **Artificial Intelligence: A Modern Approach** - *Stuart Russell, Peter Norvig* (textbook survey chapters) ğŸ“Š
- [ ] **The Quest for Artificial Intelligence** - *Nils Nilsson* (2009) ğŸ“Š
  - AIå†å²ç»¼è¿°

---

## æœºå™¨å­¦ä¹ åŸºç¡€

### ç»Ÿè®¡å­¦ä¹ ç†è®º
- [ ] **The Nature of Statistical Learning Theory** - *Vladimir Vapnik* (1995) â­ğŸ”¥
  - VCç»´ç†è®º
  - ç»Ÿè®¡å­¦ä¹ ç†è®ºå¥ åŸº
  - *Springer*

- [ ] **A Theory of the Learnable** - *Leslie Valiant* (1984) â­ğŸ†
  - PACå­¦ä¹ ç†è®º
  - *Communications of the ACM* 27

### æ”¯æŒå‘é‡æœº
- [ ] **Support-Vector Networks** - *Corinna Cortes, Vladimir Vapnik* (1995) â­ğŸ”¥
  - SVM
  - *Machine Learning* 20

- [ ] **A Training Algorithm for Optimal Margin Classifiers** - *Bernhard Boser, Isabelle Guyon, Vladimir Vapnik* (1992) â­
  - æ ¸æŠ€å·§ä¸SVM
  - *COLT 1992*

### å†³ç­–æ ‘ä¸é›†æˆå­¦ä¹ 
- [ ] **Induction of Decision Trees** - *J. Ross Quinlan* (1986) ğŸ”¥
  - ID3ç®—æ³•
  - *Machine Learning* 1

- [ ] **C4.5: Programs for Machine Learning** - *J. Ross Quinlan* (1993) ğŸ”¥
  - C4.5ç®—æ³•
  - *Morgan Kaufmann*

- [ ] **Random Forests** - *Leo Breiman* (2001) ğŸ”¥
  - éšæœºæ£®æ—
  - *Machine Learning* 45

- [ ] **A Decision-Theoretic Generalization of On-Line Learning** - *Yoav Freund, Robert Schapire* (1997) ğŸ”¥
  - AdaBoost
  - *Journal of Computer and System Sciences* 55

- [ ] **Greedy Function Approximation: A Gradient Boosting Machine** - *Jerome Friedman* (2001) ğŸ”¥
  - Gradient Boosting
  - *Annals of Statistics* 29

### è´å¶æ–¯å­¦ä¹ 
- [ ] **Learning Bayesian Networks** - *David Heckerman* (1995) ğŸ“Š
  - è´å¶æ–¯ç½‘ç»œç»¼è¿°
  - *Machine Learning* 20

- [ ] **Latent Dirichlet Allocation** - *David Blei, Andrew Ng, Michael Jordan* (2003) ğŸ”¥
  - LDAä¸»é¢˜æ¨¡å‹
  - *JMLR* 3

### ç»´åº¦çº¦ç®€
- [ ] **Principal Component Analysis** - *Karl Pearson* (1901) â­
  - PCA
  - *Philosophical Magazine* 2

- [ ] **Nonlinear Dimensionality Reduction by Locally Linear Embedding** - *Sam Roweis, Lawrence Saul* (2000) ğŸ”¥
  - LLE
  - *Science* 290

- [ ] **A Global Geometric Framework for Nonlinear Dimensionality Reduction** - *Joshua Tenenbaum, Vin de Silva, John Langford* (2000) ğŸ”¥
  - Isomap
  - *Science* 290

- [ ] **Visualizing Data using t-SNE** - *Laurens van der Maaten, Geoffrey Hinton* (2008) ğŸ”¥
  - t-SNE
  - *JMLR* 9

### ç»¼è¿°æ–‡ç« 
- [ ] **Machine Learning** - *Tom Mitchell* (1997) ğŸ“Š
  - æœºå™¨å­¦ä¹ ç»å…¸æ•™æ
- [ ] **The Elements of Statistical Learning** - *Hastie, Tibshirani, Friedman* ğŸ“Š
  - ç»Ÿè®¡å­¦ä¹ ç»¼è¿°

---

## æ·±åº¦å­¦ä¹ 

### ç¥ç»ç½‘ç»œåŸºç¡€
- [ ] **Learning Representations by Back-propagating Errors** - *David Rumelhart, Geoffrey Hinton, Ronald Williams* (1986) â­ğŸ”¥
  - åå‘ä¼ æ’­ç®—æ³•
  - *Nature* 323

- [ ] **Gradient-Based Learning Applied to Document Recognition** - *Yann LeCun et al.* (1998) â­ğŸ”¥
  - LeNet-5
  - CNNåº”ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«
  - *Proceedings of the IEEE* 86

### æ·±åº¦å­¦ä¹ å¤å…´
- [ ] **A Fast Learning Algorithm for Deep Belief Nets** - *Geoffrey Hinton, Simon Osindero, Yee-Whye Teh* (2006) â­ğŸ†
  - DBN
  - æ·±åº¦å­¦ä¹ å¤å…´
  - *Neural Computation* 18

- [ ] **Reducing the Dimensionality of Data with Neural Networks** - *Geoffrey Hinton, Ruslan Salakhutdinov* (2006) â­ğŸ†
  - æ·±åº¦è‡ªç¼–ç å™¨
  - *Science* 313

### ImageNetæ—¶ä»£
- [ ] **ImageNet Classification with Deep Convolutional Neural Networks** - *Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton* (2012) â­ğŸ†ğŸ”¥
  - AlexNet
  - æ·±åº¦å­¦ä¹ çªç ´
  - *NIPS 2012*

- [ ] **Very Deep Convolutional Networks for Large-Scale Image Recognition** - *Karen Simonyan, Andrew Zisserman* (2014) ğŸ”¥
  - VGGNet
  - *ICLR 2015*

- [ ] **Going Deeper with Convolutions** - *Christian Szegedy et al.* (2015) ğŸ”¥
  - GoogLeNet/Inception
  - *CVPR 2015*

- [ ] **Deep Residual Learning for Image Recognition** - *Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun* (2016) â­ğŸ”¥
  - ResNet
  - æ®‹å·®è¿æ¥
  - *CVPR 2016*

- [ ] **Densely Connected Convolutional Networks** - *Gao Huang et al.* (2017) ğŸ”¥
  - DenseNet
  - *CVPR 2017*

### ä¼˜åŒ–ä¸æ­£åˆ™åŒ–
- [ ] **Batch Normalization: Accelerating Deep Network Training** - *Sergey Ioffe, Christian Szegedy* (2015) ğŸ”¥
  - Batch Normalization
  - *ICML 2015*

- [ ] **Layer Normalization** - *Jimmy Ba, Jamie Kiros, Geoffrey Hinton* (2016) ğŸ”¥
  - Layer Normalization
  - *arXiv:1607.06450*

- [ ] **Dropout: A Simple Way to Prevent Neural Networks from Overfitting** - *Nitish Srivastava et al.* (2014) ğŸ”¥
  - Dropout
  - *JMLR* 15

- [ ] **Adam: A Method for Stochastic Optimization** - *Diederik Kingma, Jimmy Ba* (2014) ğŸ”¥
  - Adamä¼˜åŒ–å™¨
  - *ICLR 2015*

### ç»¼è¿°æ–‡ç« 
- [ ] **Deep Learning** - *Yann LeCun, Yoshua Bengio, Geoffrey Hinton* (2015) ğŸ“ŠğŸ†
  - *Nature* 521
  - æ·±åº¦å­¦ä¹ ç»¼è¿°

- [ ] **Deep Learning in Neural Networks: An Overview** - *JÃ¼rgen Schmidhuber* (2015) ğŸ“Š
  - *Neural Networks* 61
  - æ·±åº¦å­¦ä¹ å†å²ç»¼è¿°

---

## è®¡ç®—æœºè§†è§‰

### ç›®æ ‡æ£€æµ‹
- [ ] **Rich Feature Hierarchies for Accurate Object Detection** - *Ross Girshick et al.* (2014) â­ğŸ”¥
  - R-CNN
  - *CVPR 2014*

- [ ] **Fast R-CNN** - *Ross Girshick* (2015) ğŸ”¥
  - *ICCV 2015*

- [ ] **Faster R-CNN: Towards Real-Time Object Detection** - *Shaoqing Ren et al.* (2015) ğŸ”¥
  - *NIPS 2015*

- [ ] **You Only Look Once: Unified, Real-Time Object Detection** - *Joseph Redmon et al.* (2016) ğŸ”¥
  - YOLO
  - *CVPR 2016*

- [ ] **SSD: Single Shot MultiBox Detector** - *Wei Liu et al.* (2016) ğŸ”¥
  - *ECCV 2016*

### è¯­ä¹‰åˆ†å‰²
- [ ] **Fully Convolutional Networks for Semantic Segmentation** - *Jonathan Long, Evan Shelhamer, Trevor Darrell* (2015) â­ğŸ”¥
  - FCN
  - *CVPR 2015*

- [ ] **U-Net: Convolutional Networks for Biomedical Image Segmentation** - *Olaf Ronneberger et al.* (2015) ğŸ”¥
  - U-Net
  - *MICCAI 2015*

- [ ] **Mask R-CNN** - *Kaiming He et al.* (2017) ğŸ”¥
  - å®ä¾‹åˆ†å‰²
  - *ICCV 2017*

### å›¾åƒç”Ÿæˆä¸é£æ ¼è¿ç§»
- [ ] **A Neural Algorithm of Artistic Style** - *Leon Gatys, Alexander Ecker, Matthias Bethge* (2015) ğŸ”¥
  - ç¥ç»é£æ ¼è¿ç§»
  - *arXiv:1508.06576*

- [ ] **Image-to-Image Translation with Conditional Adversarial Networks** - *Phillip Isola et al.* (2017) ğŸ”¥
  - Pix2Pix
  - *CVPR 2017*

- [ ] **Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks** - *Jun-Yan Zhu et al.* (2017) ğŸ”¥
  - CycleGAN
  - *ICCV 2017*

### Vision Transformer
- [ ] **An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale** - *Alexey Dosovitskiy et al.* (2021) â­ğŸ”¥
  - Vision Transformer (ViT)
  - *ICLR 2021*

### ç»¼è¿°æ–‡ç« 
- [ ] **Object Detection: A Survey** - *Various Authors* ğŸ“Š
- [ ] **Image Segmentation Using Deep Learning: A Survey** - *Shervin Minaee et al.* (2021) ğŸ“Š

---

## è‡ªç„¶è¯­è¨€å¤„ç†

### è¯å‘é‡
- [ ] **A Neural Probabilistic Language Model** - *Yoshua Bengio et al.* (2003) â­ğŸ†
  - ç¥ç»è¯­è¨€æ¨¡å‹
  - *JMLR* 3

- [ ] **Efficient Estimation of Word Representations in Vector Space** - *Tomas Mikolov et al.* (2013) â­ğŸ”¥
  - Word2Vec
  - *arXiv:1301.3781*

- [ ] **GloVe: Global Vectors for Word Representation** - *Jeffrey Pennington, Richard Socher, Christopher Manning* (2014) ğŸ”¥
  - GloVe
  - *EMNLP 2014*

### åºåˆ—æ¨¡å‹
- [ ] **Long Short-Term Memory** - *Sepp Hochreiter, JÃ¼rgen Schmidhuber* (1997) â­ğŸ”¥
  - LSTM
  - *Neural Computation* 9

- [ ] **Learning Phrase Representations using RNN Encoder-Decoder** - *Kyunghyun Cho et al.* (2014) ğŸ”¥
  - GRU
  - *EMNLP 2014*

- [ ] **Sequence to Sequence Learning with Neural Networks** - *Ilya Sutskever, Oriol Vinyals, Quoc Le* (2014) â­ğŸ”¥
  - Seq2Seq
  - *NIPS 2014*

### æ³¨æ„åŠ›æœºåˆ¶ä¸Transformer
- [ ] **Neural Machine Translation by Jointly Learning to Align and Translate** - *Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio* (2014) â­ğŸ”¥
  - æ³¨æ„åŠ›æœºåˆ¶
  - *ICLR 2015*

- [ ] **Attention Is All You Need** - *Ashish Vaswani et al.* (2017) â­ğŸ”¥
  - Transformer
  - *NIPS 2017*

### é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
- [ ] **BERT: Pre-training of Deep Bidirectional Transformers** - *Jacob Devlin et al.* (2018) â­ğŸ”¥
  - BERT
  - *NAACL 2019*

- [ ] **Improving Language Understanding by Generative Pre-Training** - *Alec Radford et al.* (2018) â­ğŸ”¥
  - GPT
  - OpenAI Technical Report

- [ ] **Language Models are Unsupervised Multitask Learners** - *Alec Radford et al.* (2019) â­ğŸ”¥
  - GPT-2
  - OpenAI Technical Report

- [ ] **Language Models are Few-Shot Learners** - *Tom Brown et al.* (2020) â­ğŸ”¥
  - GPT-3
  - *NeurIPS 2020*

- [ ] **T5: Exploring the Limits of Transfer Learning** - *Colin Raffel et al.* (2020) ğŸ”¥
  - T5
  - *JMLR* 21

### å¤§è¯­è¨€æ¨¡å‹
- [ ] **Training language models to follow instructions with human feedback** - *Long Ouyang et al.* (2022) â­ğŸ”¥
  - InstructGPT
  - ChatGPTåŸºç¡€
  - *arXiv:2203.02155*

- [ ] **LLaMA: Open and Efficient Foundation Language Models** - *Hugo Touvron et al.* (2023) ğŸ”¥
  - LLaMA
  - *arXiv:2302.13971*

- [ ] **GPT-4 Technical Report** - *OpenAI* (2023) â­ğŸ”¥
  - GPT-4
  - *arXiv:2303.08774*

### ç»¼è¿°æ–‡ç« 
- [ ] **Recent Advances in Deep Learning for Natural Language Processing** - *Various Authors* ğŸ“Š
- [ ] **Pre-trained Models for Natural Language Processing: A Survey** - *Xipeng Qiu et al.* (2020) ğŸ“Š

---

## å¼ºåŒ–å­¦ä¹ 

### åŸºç¡€ç®—æ³•
- [ ] **Learning from Delayed Rewards** - *Chris Watkins* (1989) â­
  - Q-learning
  - PhD Thesis, Cambridge

- [ ] **Simple Statistical Gradient-Following Algorithms for Connectionist RL** - *Ronald Williams* (1992) â­
  - REINFORCE
  - *Machine Learning* 8

- [ ] **Temporal Difference Learning and TD-Gammon** - *Gerald Tesauro* (1995) ğŸ”¥
  - TD-Gammon
  - *Communications of the ACM* 38

### æ·±åº¦å¼ºåŒ–å­¦ä¹ 
- [ ] **Playing Atari with Deep Reinforcement Learning** - *Volodymyr Mnih et al.* (2013) â­ğŸ”¥
  - DQN
  - *NIPS Deep Learning Workshop*

- [ ] **Human-level control through deep reinforcement learning** - *Volodymyr Mnih et al.* (2015) â­ğŸ”¥
  - DQNå®Œæ•´ç‰ˆ
  - *Nature* 518

- [ ] **Deep Reinforcement Learning with Double Q-learning** - *Hado van Hasselt, Arthur Guez, David Silver* (2016) ğŸ”¥
  - Double DQN
  - *AAAI 2016*

- [ ] **Dueling Network Architectures for Deep Reinforcement Learning** - *Ziyu Wang et al.* (2016) ğŸ”¥
  - Dueling DQN
  - *ICML 2016*

### Policy Gradientæ–¹æ³•
- [ ] **Policy Gradient Methods for Reinforcement Learning with Function Approximation** - *Richard Sutton et al.* (1999) â­
  - Policy Gradient
  - *NIPS 1999*

- [ ] **Asynchronous Methods for Deep Reinforcement Learning** - *Volodymyr Mnih et al.* (2016) ğŸ”¥
  - A3C
  - *ICML 2016*

- [ ] **Proximal Policy Optimization Algorithms** - *John Schulman et al.* (2017) ğŸ”¥
  - PPO
  - *arXiv:1707.06347*

- [ ] **Trust Region Policy Optimization** - *John Schulman et al.* (2015) ğŸ”¥
  - TRPO
  - *ICML 2015*

### Actor-Criticæ–¹æ³•
- [ ] **Deterministic Policy Gradient Algorithms** - *David Silver et al.* (2014) ğŸ”¥
  - DPG
  - *ICML 2014*

- [ ] **Continuous Control with Deep Reinforcement Learning** - *Timothy Lillicrap et al.* (2016) ğŸ”¥
  - DDPG
  - *ICLR 2016*

- [ ] **Soft Actor-Critic** - *Tuomas Haarnoja et al.* (2018) ğŸ”¥
  - SAC
  - *ICML 2018*

### æ¨¡å‹å‹RL
- [ ] **World Models** - *David Ha, JÃ¼rgen Schmidhuber* (2018) ğŸ”¥
  - *arXiv:1803.10122*

- [ ] **Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model** - *Julian Schrittwieser et al.* (2020) ğŸ”¥
  - MuZero
  - *Nature* 588

### AlphaGoç³»åˆ—
- [ ] **Mastering the game of Go with deep neural networks and tree search** - *David Silver et al.* (2016) â­ğŸ”¥
  - AlphaGo
  - *Nature* 529

- [ ] **Mastering the game of Go without human knowledge** - *David Silver et al.* (2017) â­ğŸ”¥
  - AlphaGo Zero
  - *Nature* 550

- [ ] **A general reinforcement learning algorithm that masters chess, shogi, and Go** - *David Silver et al.* (2018) ğŸ”¥
  - AlphaZero
  - *Science* 362

### ç»¼è¿°æ–‡ç« 
- [ ] **Reinforcement Learning: A Survey** - *Leslie Kaelbling, Michael Littman, Andrew Moore* (1996) ğŸ“Š
  - *JAIR* 4
- [ ] **Deep Reinforcement Learning: A Survey** - *Kai Arulkumaran et al.* (2017) ğŸ“Š

---

## ç”Ÿæˆæ¨¡å‹

### å˜åˆ†è‡ªç¼–ç å™¨
- [ ] **Auto-Encoding Variational Bayes** - *Diederik Kingma, Max Welling* (2013) â­ğŸ”¥
  - VAE
  - *ICLR 2014*

### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
- [ ] **Generative Adversarial Networks** - *Ian Goodfellow et al.* (2014) â­ğŸ”¥
  - GAN
  - *NIPS 2014*

- [ ] **Conditional Generative Adversarial Nets** - *Mehdi Mirza, Simon Osindero* (2014) ğŸ”¥
  - cGAN
  - *arXiv:1411.1784*

- [ ] **Unsupervised Representation Learning with DCGAN** - *Alec Radford, Luke Metz, Soumith Chintala* (2016) ğŸ”¥
  - DCGAN
  - *ICLR 2016*

- [ ] **Progressive Growing of GANs** - *Tero Karras et al.* (2018) ğŸ”¥
  - Progressive GAN
  - *ICLR 2018*

- [ ] **A Style-Based Generator Architecture for GANs** - *Tero Karras, Samuli Laine, Timo Aila* (2019) ğŸ”¥
  - StyleGAN
  - *CVPR 2019*

### æ‰©æ•£æ¨¡å‹
- [ ] **Denoising Diffusion Probabilistic Models** - *Jonathan Ho, Ajay Jain, Pieter Abbeel* (2020) â­ğŸ”¥
  - DDPM
  - *NeurIPS 2020*

- [ ] **Improved Denoising Diffusion Probabilistic Models** - *Alex Nichol, Prafulla Dhariwal* (2021) ğŸ”¥
  - *ICML 2021*

- [ ] **High-Resolution Image Synthesis with Latent Diffusion Models** - *Robin Rombach et al.* (2022) â­ğŸ”¥
  - Stable Diffusion
  - *CVPR 2022*

- [ ] **Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding** - *Chitwan Saharia et al.* (2022) ğŸ”¥
  - Imagen
  - *NeurIPS 2022*

### æµæ¨¡å‹
- [ ] **NICE: Non-linear Independent Components Estimation** - *Laurent Dinh, David Krueger, Yoshua Bengio* (2015) ğŸ”¥
  - *ICLR Workshop 2015*

- [ ] **Density Estimation using Real NVP** - *Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio* (2017) ğŸ”¥
  - *ICLR 2017*

- [ ] **Glow: Generative Flow Models** - *Diederik Kingma, Prafulla Dhariwal* (2018) ğŸ”¥
  - *NeurIPS 2018*

### ç»¼è¿°æ–‡ç« 
- [ ] **Generative Modeling: A Survey** - *Various Authors* ğŸ“Š
- [ ] **Diffusion Models: A Comprehensive Survey** - *Ling Yang et al.* (2023) ğŸ“Š

---

## å›¾ç¥ç»ç½‘ç»œ

### GNNåŸºç¡€
- [ ] **The Graph Neural Network Model** - *Franco Scarselli et al.* (2009) â­
  - GNNæ¦‚å¿µæå‡º
  - *IEEE Transactions on Neural Networks* 20

- [ ] **Spectral Networks and Locally Connected Networks on Graphs** - *Joan Bruna et al.* (2014) â­
  - è°±å›¾å·ç§¯
  - *ICLR 2014*

- [ ] **Semi-Supervised Classification with Graph Convolutional Networks** - *Thomas Kipf, Max Welling* (2017) â­ğŸ”¥
  - GCN
  - *ICLR 2017*

- [ ] **Inductive Representation Learning on Large Graphs** - *William Hamilton, Rex Ying, Jure Leskovec* (2017) ğŸ”¥
  - GraphSAGE
  - *NIPS 2017*

- [ ] **Graph Attention Networks** - *Petar VeliÄkoviÄ‡ et al.* (2018) ğŸ”¥
  - GAT
  - *ICLR 2018*

### å›¾ç”Ÿæˆä¸é¢„è®­ç»ƒ
- [ ] **Graph Isomorphism Network** - *Keyulu Xu et al.* (2019) ğŸ”¥
  - GIN
  - *ICLR 2019*

- [ ] **How Powerful are Graph Neural Networks?** - *Keyulu Xu et al.* (2019) ğŸ”¥
  - GNNè¡¨è¾¾èƒ½åŠ›
  - *ICLR 2019*

### ç»¼è¿°æ–‡ç« 
- [ ] **A Comprehensive Survey on Graph Neural Networks** - *Zonghan Wu et al.* (2020) ğŸ“Š
  - *IEEE TNNLS*
- [ ] **Graph Representation Learning: A Survey** - *William Hamilton* (2020) ğŸ“Š

---

## å…ƒå­¦ä¹ ä¸è¿ç§»å­¦ä¹ 

### å…ƒå­¦ä¹ 
- [ ] **Model-Agnostic Meta-Learning for Fast Adaptation** - *Chelsea Finn, Pieter Abbeel, Sergey Levine* (2017) â­ğŸ”¥
  - MAML
  - *ICML 2017*

- [ ] **Matching Networks for One Shot Learning** - *Oriol Vinyals et al.* (2016) ğŸ”¥
  - *NIPS 2016*

- [ ] **Prototypical Networks for Few-shot Learning** - *Jake Snell, Kevin Swersky, Richard Zemel* (2017) ğŸ”¥
  - *NIPS 2017*

### è¿ç§»å­¦ä¹ 
- [ ] **How transferable are features in deep neural networks?** - *Jason Yosinski et al.* (2014) ğŸ”¥
  - *NIPS 2014*

- [ ] **Domain-Adversarial Training of Neural Networks** - *Yaroslav Ganin et al.* (2016) ğŸ”¥
  - Domain Adaptation
  - *JMLR* 17

### å¤šä»»åŠ¡å­¦ä¹ 
- [ ] **Multi-Task Learning Using Uncertainty to Weigh Losses** - *Alex Kendall, Yarin Gal, Roberto Cipolla* (2018) ğŸ”¥
  - *CVPR 2018*

### ç»¼è¿°æ–‡ç« 
- [ ] **Meta-Learning: A Survey** - *Joaquin Vanschoren* (2018) ğŸ“Š
- [ ] **A Survey on Transfer Learning** - *Sinno Pan, Qiang Yang* (2010) ğŸ“Š

---

## AIåº”ç”¨ä¸ç³»ç»Ÿ

### æ¨èç³»ç»Ÿ
- [ ] **Amazon.com Recommendations: Item-to-Item Collaborative Filtering** - *Greg Linden, Brent Smith, Jeremy York* (2003) ğŸ”¥
  - *IEEE Internet Computing* 7

- [ ] **The BellKor Solution to the Netflix Grand Prize** - *Yehuda Koren* (2009) ğŸ”¥
  - Netflix Prize
  - *Netflix Prize Documentation*

- [ ] **DeepFM: A Factorization-Machine based Neural Network** - *Huifeng Guo et al.* (2017) ğŸ”¥
  - *IJCAI 2017*

- [ ] **Neural Collaborative Filtering** - *Xiangnan He et al.* (2017) ğŸ”¥
  - *WWW 2017*

### è¯­éŸ³è¯†åˆ«
- [ ] **Deep Neural Networks for Acoustic Modeling in Speech Recognition** - *Geoffrey Hinton et al.* (2012) ğŸ”¥
  - DNN-HMM
  - *IEEE Signal Processing Magazine* 29

- [ ] **Listen, Attend and Spell** - *William Chan et al.* (2016) ğŸ”¥
  - ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«
  - *ICASSP 2016*

- [ ] **wav2vec 2.0: A Framework for Self-Supervised Learning** - *Alexei Baevski et al.* (2020) ğŸ”¥
  - *NeurIPS 2020*

### åŒ»ç–—AI
- [ ] **Deep Learning for Detecting Diabetic Retinopathy** - *Varun Gulshan et al.* (2016) ğŸ”¥
  - *JAMA* 316

- [ ] **Dermatologist-level classification of skin cancer** - *Andre Esteva et al.* (2017) ğŸ”¥
  - *Nature* 542

### AIç³»ç»Ÿä¸å·¥ç¨‹
- [ ] **TensorFlow: A System for Large-Scale Machine Learning** - *MartÃ­n Abadi et al.* (2016) ğŸ”¥
  - *OSDI 2016*

- [ ] **PyTorch: An Imperative Style, High-Performance Deep Learning Library** - *Adam Paszke et al.* (2019) ğŸ”¥
  - *NeurIPS 2019*

- [ ] **XGBoost: A Scalable Tree Boosting System** - *Tianqi Chen, Carlos Guestrin* (2016) ğŸ”¥
  - *KDD 2016*

### ç»¼è¿°æ–‡ç« 
- [ ] **Deep Learning for Recommender Systems: A Survey** - *Shuai Zhang et al.* (2019) ğŸ“Š
- [ ] **AI Systems: A Survey** - *Various Authors* ğŸ“Š

---

## é™„å½•ï¼šæœŸåˆŠä¸èµ„æº

### é¡¶çº§AI/MLä¼šè®®
1. **NeurIPS** - ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿ
2. **ICML** - å›½é™…æœºå™¨å­¦ä¹ ä¼šè®®
3. **ICLR** - å›½é™…å­¦ä¹ è¡¨å¾ä¼šè®®
4. **CVPR** - è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«
5. **ICCV** - å›½é™…è®¡ç®—æœºè§†è§‰ä¼šè®®
6. **ECCV** - æ¬§æ´²è®¡ç®—æœºè§†è§‰ä¼šè®®
7. **ACL** - è®¡ç®—è¯­è¨€å­¦åä¼šå¹´ä¼š
8. **EMNLP** - è‡ªç„¶è¯­è¨€å¤„ç†å®è¯æ–¹æ³•
9. **AAAI** - äººå·¥æ™ºèƒ½åä¼šä¼šè®®
10. **IJCAI** - å›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®

### é¡¶çº§AI/MLæœŸåˆŠ
1. **JMLR** - Journal of Machine Learning Research
2. **TPAMI** - IEEE Trans. on Pattern Analysis and Machine Intelligence
3. **JAIR** - Journal of Artificial Intelligence Research
4. **Machine Learning** - Springer
5. **Neural Networks** - Elsevier
6. **Neural Computation** - MIT Press

### ä¸»è¦AIæ•°æ®åº“ä¸èµ„æº
- **arXiv.org (cs.AI, cs.LG, cs.CV, cs.CL)** - AIé¢„å°æœ¬åº“
- **Papers with Code** - è®ºæ–‡ä¸ä»£ç é›†åˆ
- **OpenReview** - ICLRç­‰ä¼šè®®è¯„å®¡å¹³å°
- **Google Scholar** - å­¦æœ¯æœç´¢
- **Semantic Scholar** - AIé©±åŠ¨çš„å­¦æœ¯æœç´¢

### é‡è¦ç»¼è¿°æœŸåˆŠ
- **Foundations and Trends in ML**
- **Artificial Intelligence Review**
- **ACM Computing Surveys** - AIç›¸å…³ç»¼è¿°

### æ•°æ®é›†èµ„æº
- **ImageNet** - å¤§è§„æ¨¡å›¾åƒåˆ†ç±»
- **COCO** - ç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²
- **OpenAI Gym** - å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ
- **Hugging Face Datasets** - NLPæ•°æ®é›†

### å­¦ä¹ èµ„æº
- **Distill.pub** - æœºå™¨å­¦ä¹ å¯è§†åŒ–è§£é‡Š
- **Papers We Love** - ç»å…¸è®ºæ–‡é˜…è¯»
- **Yannic Kilcher YouTube** - è®ºæ–‡è§£è¯»
- **Two Minute Papers** - è®ºæ–‡å¿«é€Ÿè§£è¯»

### é˜…è¯»å»ºè®®
1. ä»ç»¼è¿°æ–‡ç« å’Œæ•™æå¼€å§‹
2. å…³æ³¨é¡¶çº§ä¼šè®®æœ€æ–°è®ºæ–‡
3. è·Ÿè¸ªarXivä¸Šçš„é¢„å°æœ¬
4. ä½¿ç”¨Papers with Codeæ‰¾ä»£ç å®ç°
5. é˜…è¯»åšå®¢å’Œè§†é¢‘ç†è§£ç›´è§‰
6. å¤ç°ç»å…¸è®ºæ–‡åŠ æ·±ç†è§£

---

**å¤‡æ³¨ï¼š**
- æœ¬æ¸…å•ä¾§é‡äº2010å¹´åæ·±åº¦å­¦ä¹ æ—¶ä»£çš„çªç ´
- ä¹ŸåŒ…å«æ—©æœŸAIå’Œç»å…¸æœºå™¨å­¦ä¹ å¥ åŸºå·¥ä½œ
- è®ºæ–‡é€‰æ‹©æ ‡å‡†ï¼šå½±å“åŠ›ã€å¼•ç”¨æ•°ã€å†å²é‡è¦æ€§
- AIé¢†åŸŸå‘å±•æå¿«ï¼Œå»ºè®®æŒç»­å…³æ³¨æœ€æ–°è¿›å±•
- è®¸å¤šé‡è¦å·¥ä½œé¦–å‘äºarXivï¼Œåæ­£å¼å‘è¡¨

**æœ€åæ›´æ–°ï¼š** 2025å¹´12æœˆ
